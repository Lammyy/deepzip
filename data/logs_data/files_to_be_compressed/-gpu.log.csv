Starting training ...
Starting Compression ...
Using TensorFlow backend.
usage: compressor.py [-h] [-model MODEL_WEIGHTS_FILE] [-model_name MODEL_NAME]
                     [-batch_size BATCH_SIZE] [-data SEQUENCE_NPY_FILE]
                     [-data_params PARAMS_FILE] [-output OUTPUT_FILE_PREFIX]
compressor.py: error: argument -model_name: expected one argument
Command exited with non-zero status 2
	Command being timed: "python compressor.py -data ../data/processed_files/files_to_be_compressed.npy -data_params ../data/processed_files/files_to_be_compressed.param.json -model ../data/trained_models/files_to_be_compressed/-gpu.hdf5 -model_name -gpu -output ../data/compressed/files_to_be_compressed/-gpu.compressed -batch_size 1000"
	User time (seconds): 2.08
	System time (seconds): 0.27
	Percent of CPU this job got: 92%
	Elapsed (wall clock) time (h:mm:ss or m:ss): 0:02.54
	Average shared text size (kbytes): 0
	Average unshared data size (kbytes): 0
	Average stack size (kbytes): 0
	Average total size (kbytes): 0
	Maximum resident set size (kbytes): 232652
	Average resident set size (kbytes): 0
	Major (requiring I/O) page faults: 0
	Minor (reclaiming a frame) page faults: 61940
	Voluntary context switches: 3278
	Involuntary context switches: 83
	Swaps: 0
	File system inputs: 0
	File system outputs: 8
	Socket messages sent: 0
	Socket messages received: 0
	Signals delivered: 0
	Page size (bytes): 4096
	Exit status: 2
Using TensorFlow backend.
usage: decompressor.py [-h] [-model MODEL_WEIGHTS_FILE]
                       [-model_name MODEL_NAME] [-batch_size BATCH_SIZE]
                       [-output OUTPUT_FILE_NAME]
                       [-input_file_prefix INPUT_FILE_PREFIX]
decompressor.py: error: argument -model_name: expected one argument
Command exited with non-zero status 2
	Command being timed: "python decompressor.py -output ../data/compressed/files_to_be_compressed/-gpu.reconstructed.txt -model ../data/trained_models/files_to_be_compressed/-gpu.hdf5 -model_name -gpu -input_file_prefix ../data/compressed/files_to_be_compressed/-gpu.compressed -batch_size 1000"
	User time (seconds): 2.08
	System time (seconds): 0.26
	Percent of CPU this job got: 92%
	Elapsed (wall clock) time (h:mm:ss or m:ss): 0:02.53
	Average shared text size (kbytes): 0
	Average unshared data size (kbytes): 0
	Average stack size (kbytes): 0
	Average total size (kbytes): 0
	Maximum resident set size (kbytes): 232388
	Average resident set size (kbytes): 0
	Major (requiring I/O) page faults: 0
	Minor (reclaiming a frame) page faults: 61785
	Voluntary context switches: 3276
	Involuntary context switches: 85
	Swaps: 0
	File system inputs: 0
	File system outputs: 8
	Socket messages sent: 0
	Socket messages received: 0
	Signals delivered: 0
	Page size (bytes): 4096
	Exit status: 2
Starting training ...
Starting Compression ...
Using TensorFlow backend.
usage: compressor.py [-h] [-model MODEL_WEIGHTS_FILE] [-model_name MODEL_NAME]
                     [-batch_size BATCH_SIZE] [-data SEQUENCE_NPY_FILE]
                     [-data_params PARAMS_FILE] [-output OUTPUT_FILE_PREFIX]
compressor.py: error: argument -model_name: expected one argument
Command exited with non-zero status 2
	Command being timed: "python compressor.py -data ../data/processed_files/files_to_be_compressed.npy -data_params ../data/processed_files/files_to_be_compressed.param.json -model ../data/trained_models/files_to_be_compressed/-gpu.hdf5 -model_name -gpu -output ../data/compressed/files_to_be_compressed/-gpu.compressed -batch_size 1000"
	User time (seconds): 2.07
	System time (seconds): 0.26
	Percent of CPU this job got: 93%
	Elapsed (wall clock) time (h:mm:ss or m:ss): 0:02.50
	Average shared text size (kbytes): 0
	Average unshared data size (kbytes): 0
	Average stack size (kbytes): 0
	Average total size (kbytes): 0
	Maximum resident set size (kbytes): 232392
	Average resident set size (kbytes): 0
	Major (requiring I/O) page faults: 0
	Minor (reclaiming a frame) page faults: 62288
	Voluntary context switches: 3294
	Involuntary context switches: 85
	Swaps: 0
	File system inputs: 0
	File system outputs: 8
	Socket messages sent: 0
	Socket messages received: 0
	Signals delivered: 0
	Page size (bytes): 4096
	Exit status: 2
Using TensorFlow backend.
usage: decompressor.py [-h] [-model MODEL_WEIGHTS_FILE]
                       [-model_name MODEL_NAME] [-batch_size BATCH_SIZE]
                       [-output OUTPUT_FILE_NAME]
                       [-input_file_prefix INPUT_FILE_PREFIX]
decompressor.py: error: argument -model_name: expected one argument
Command exited with non-zero status 2
	Command being timed: "python decompressor.py -output ../data/compressed/files_to_be_compressed/-gpu.reconstructed.txt -model ../data/trained_models/files_to_be_compressed/-gpu.hdf5 -model_name -gpu -input_file_prefix ../data/compressed/files_to_be_compressed/-gpu.compressed -batch_size 1000"
	User time (seconds): 2.04
	System time (seconds): 0.30
	Percent of CPU this job got: 94%
	Elapsed (wall clock) time (h:mm:ss or m:ss): 0:02.49
	Average shared text size (kbytes): 0
	Average unshared data size (kbytes): 0
	Average stack size (kbytes): 0
	Average total size (kbytes): 0
	Maximum resident set size (kbytes): 232328
	Average resident set size (kbytes): 0
	Major (requiring I/O) page faults: 0
	Minor (reclaiming a frame) page faults: 62435
	Voluntary context switches: 3276
	Involuntary context switches: 85
	Swaps: 0
	File system inputs: 0
	File system outputs: 8
	Socket messages sent: 0
	Socket messages received: 0
	Signals delivered: 0
	Page size (bytes): 4096
	Exit status: 2
